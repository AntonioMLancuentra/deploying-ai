{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6711f7",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We will start with a discussion on APIs, then we will setup our Jupyter notebook, and then we conquer the LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe804593",
   "metadata": {},
   "source": [
    "# Application Programming Interfaces\n",
    "\n",
    "An Application Programming Interface or API is a mechanisms that enables two software components to communicate with each other using a set of definitions and protocols. ([AWS](https://aws.amazon.com/what-is/api/))\n",
    "\n",
    "+ An *application* is any software with a distinct function. \n",
    "+ An *interface* can be seen as a contract between two applications that specifies how they will communicate with each other.\n",
    "\n",
    "![](./img/01_api.svg)\n",
    "\n",
    "## Types of APIs\n",
    "\n",
    "There are four ways API can work:\n",
    "\n",
    "### SOAP APIs\n",
    "\n",
    "+ Simple Object Access Protocol. \n",
    "+ Client and server exchange using XML. \n",
    "+ Popular in the past, but less flexible than more modern alternatives.\n",
    "\n",
    "### RPC APIs\n",
    "\n",
    "+ Remote Procedural Calls.\n",
    "+ Client completes a function (or procedure) on the server. \n",
    "+ The server sends the output back to the client.\n",
    "\n",
    "### Websocket APIs\n",
    "\n",
    "+ Uses JSON objects to pass data.\n",
    "+ Supports two-way communication between client app and server.\n",
    "+ Server can send callback messages to connected clients, making it more efficient than REST API.\n",
    "\n",
    "### REST APIs\n",
    "\n",
    "+ Representational State Transfer.\n",
    "+ Most popular and flexible APIs found today.\n",
    "+ Client sends request to the server as data.\n",
    "+ Server uses this client input to start internal functions and returns output data back to the client.\n",
    "+ Defines a set of functions like GET, PUT, DELETE, etc. that clients can use to access server data.\n",
    "+ Clients and servers exchange data using HTTP.\n",
    "+ REST APIs are stateless: servers do not save client data between requests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f299413",
   "metadata": {},
   "source": [
    "## API Endpoints\n",
    "\n",
    "API endpoints are the final touchpoints in the API communication system. API endpoints can be server URLs, services, and other specific digital locations where information is sent and received between systems.\n",
    "\n",
    "Two critical aspects about API Endpoints are:\n",
    "\n",
    "1. Security: API endpoints make the system vulnerable to attack.\n",
    "2. Performance: API endpoints, especially high traffic ones, can cause bottelnecks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c18359",
   "metadata": {},
   "source": [
    "## OpenAI's API\n",
    "\n",
    "+ The API provided by OpenAI is a useful starting point for building AI applications.\n",
    "+ The API provides endpoints for various services, for example:\n",
    "\n",
    "    - Responses API: https://api.openai.com/v1/responses\n",
    "    - Conversations API: https://api.openai.com/v1/conversations\n",
    "    - Videos API: https://api.openai.com/v1/videos\n",
    "    - Embeddings API: https://api.openai.com/v1/embeddings\n",
    "    - Eval API: https://api.openai.com/v1/evals\n",
    "\n",
    "+ As well, OpenAI offers [Software Development Kits (SDK)](https://platform.openai.com/docs/libraries#install-an-official-sdk) for their APIs. These SDKs, allow us to interact with the API with Python functions instead of forming URLs and using tools like curl. SDKs are available for Python, JavaScript, .NET, Java, and Go.\n",
    "+ The API is not the only interface to OpenAI's models and services, for example, \n",
    "\n",
    "    - Web apps are used to interact with GPT models via a chat client, [ChatGPT](https://chatgpt.com/)).\n",
    "    - Developers can create agentic workflows using [Agent Builder](https://platform.openai.com/agent-builder) a no-code/low-code alternative to the API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4079138e",
   "metadata": {},
   "source": [
    "# Authentication\n",
    "\n",
    "+ Authentication is the process of verifying the identity of a user or system.\n",
    "+ Authentication (who you are) is generally paired with authorization (what you can do). \n",
    "+ Authenticating to the OpenAI service is done through an SSH Key, Secret Key, or API Key.\n",
    "+ Details can be found in [OpenAI's API Documentation](https://platform.openai.com/docs/api-reference/introduction).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aad26e",
   "metadata": {},
   "source": [
    "## Obtaining and Using API Keys\n",
    "\n",
    "+ You can obtain OpenAI API Keys from [this page](https://platform.openai.com/api-keys).\n",
    "+ Consider the following [Best Practices for API Key Safety](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety):\n",
    "\n",
    "    1. Always use a unique API key for each team member on your account. \n",
    "    2. Never deploy your key in client-side environments like browsers or mobile apps.\n",
    "    3. Never commit your key to your repository.\n",
    "    4. Use Environment Variables in place of your API key.\n",
    "    5. Use a Key Management Service.\n",
    "    6. Monitor your account usage and rotate your keys when needed.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a712f76e",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Setup\n",
    "\n",
    "In this section we discuss a few preliminaries that will be useful throughout our lab sessions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca2330f",
   "metadata": {},
   "source": [
    "## Update System Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe751dbe",
   "metadata": {},
   "source": [
    "+ Add the folder `./05_src/` to the system path:\n",
    "    \n",
    "    - This allows us to reutilize our modules in this notebook.\n",
    "    - We can also avoid duplication as we build on top the code that we have written before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119b8186",
   "metadata": {},
   "source": [
    "+ The next cell imports the sys module and appends a relative path ('../../05_src/') to the system path.\n",
    "+ This allows Python to locate and import custom modules from that directory in subsequent cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6accefb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../05_src/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e30d88",
   "metadata": {},
   "source": [
    "## Use a Logger\n",
    "\n",
    "- A logger affords observability and retains your logs.\n",
    "- Log formats are customizable and you can include items like timestamp, module, function, line number, and so on.\n",
    "- Log level is also customizable:\n",
    "\n",
    "    + INFO for regular operations.\n",
    "    + DEBUG for development.\n",
    "    + ERROR and WARNING will be logged.\n",
    "\n",
    "- Useful documents on logging:\n",
    "\n",
    "    - [Python logging library](https://docs.python.org/3/library/logging.html).\n",
    "    - [Real Python: Logging](https://realpython.com/python-logging/).\n",
    "    - [The Hitchhiker's Guide to Python: Logging](https://docs.python-guide.org/writing/logging/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4081ef33",
   "metadata": {},
   "source": [
    "The code cell below imports the function `get_logger()` from the module `utils.logger`. Notice that this module is located in ./05_src/utils/logger.py. We can directly load the module because we added the source folder (05_src) to our system path above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bd2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logger import get_logger\n",
    "_logs = get_logger(__name__, log_dir='../../06_logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da49a967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-13 15:33:53,060, 999434666.py, 1, INFO, This is a log message.\n"
     ]
    }
   ],
   "source": [
    "_logs.info('This is a log message.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f0942",
   "metadata": {},
   "source": [
    "## Loading Environment Variables\n",
    "\n",
    "+ Environment variables are stored in the operating system environment and not declared within the application itself.\n",
    "+ They are convenient vairables to store settings such as file locations, directories, operational parameters, and log levels, among others.\n",
    "+ They can also be used to store secrets (API keys, passwords, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76d2e44",
   "metadata": {},
   "source": [
    "### Dotenv and .env\n",
    "\n",
    "We can set environment variables in the terminal window, but we can also use a convenient library called [`python-dotenv`](https://pypi.org/project/python-dotenv/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f94de8",
   "metadata": {},
   "source": [
    "From a Python module, you can call this functionality as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71fc7085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('../../05_src/.secrets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8b07fa",
   "metadata": {},
   "source": [
    "However, from a Jupyter notebook you would usually use something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b76030d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../../05_src/.env\n",
    "%dotenv ../../05_src/.secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34caf53c",
   "metadata": {},
   "source": [
    "We can obtain the the value of an enviornment variable using [`os.getenv()`](https://docs.python.org/3/library/os.html#os.getenv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99b8d22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEBUG'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getenv('LOG_LEVEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ce15f",
   "metadata": {},
   "source": [
    "### About .secrets\n",
    "\n",
    "The file .secrets is similar to .env in the sense that it contains key-value pairs meant to be set as environment variables. However, we seggregate certain variables, the secrets, into a special file which is then ignored by .git by adding it to .gitignore.\n",
    "\n",
    "A sample of the expected format of .secrets is .secrets.template."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328dd79e",
   "metadata": {},
   "source": [
    "# Hello World!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ed6301",
   "metadata": {},
   "source": [
    "We will use the [OpenAI Python API library](https://github.com/openai/openai-python?tab=readme-ov-file) as our main tool to communicate with OpenAI's API.\n",
    "\n",
    "The code cell below makes a first call to the Responses API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fecd195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How are you today?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model = 'gpt-4o',\n",
    "    input = 'Hello world!',\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795fb577",
   "metadata": {},
   "source": [
    "There are several things happening in this code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb68e77",
   "metadata": {},
   "source": [
    "1. Load the OpenAI library and instantiate a client object. The client object handles authentication, API calls, request/response handling, and error handling. In particular, it will look for an API key in an environment variable called `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05951acf",
   "metadata": {},
   "source": [
    "2. We create an API call and store the result in the variable `response`. Notice that the call specifies the model that we want to use, as well as an input. This is a simple call, the [responses API can handle more complex calls](https://platform.openai.com/docs/api-reference/responses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a3c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model = 'gpt-4o',\n",
    "    input = 'Hello world!',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844795a7",
   "metadata": {},
   "source": [
    "3. Print out `output_text` from the response. The repsonse object will contain an attribute called `output` (a list) that contains content (another list) and the content contains text. Below we show these relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4094417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How are you today?\n"
     ]
    }
   ],
   "source": [
    "print(response.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfacf829",
   "metadata": {},
   "source": [
    "In the sample code, we used a convenience attribute called `output_text` that includes a concatenation of the text in all content and all output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "753cb8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How are you today?\n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6036d3c",
   "metadata": {},
   "source": [
    "Finally, we show the JSON-serialized version of the response object. The response object offers two methods to obtain JSON and dictionary versions of the repsonse: `repsonse.to_json()` and `response.to_dict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e46b505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_01b12c63540305620068ed5b5dbab08197b1d85bea92f1ab37\",\n",
      "  \"created_at\": 1760385885.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_01b12c63540305620068ed5b5f38d481978253be0be3f8103d\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Hello! How are you today?\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": []\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": \"medium\"\n",
      "  },\n",
      "  \"top_logprobs\": 0,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 10,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 8,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 18\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"billing\": {\n",
      "    \"payer\": \"developer\"\n",
      "  },\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150e68af",
   "metadata": {},
   "source": [
    "# Longer Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f829ef4f",
   "metadata": {},
   "source": [
    "- Let's try to add more context to our prompt.\n",
    "- Python's [request](https://pypi.org/project/requests/) library and [documentation](https://requests.readthedocs.io/en/latest/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44042a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "file_url = 'https://www.gutenberg.org/cache/epub/204/pg204.txt'\n",
    "book = requests.get(file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5781e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(book.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484ffc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(book.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3aa66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "    You are a literary historian. \n",
    "    Given the following context from a book, please summarize it in a concise manner. \n",
    "    Use no more than 4 sentences. \n",
    "    The book is the following: \\n {book.text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dad9872",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model = 'gpt-4o',\n",
    "    input = prompt,\n",
    ")\n",
    "response.output[0].content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86928b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e353e82",
   "metadata": {},
   "source": [
    "**Note**: From the [documentation](https://platform.openai.com/docs/guides/text?api-mode=responses) we know that,\n",
    "\n",
    "> The output array often has more than one item in it! It can contain tool calls, data about reasoning tokens generated by reasoning models, and other items. It is not safe to assume that the model's text output is present at output[0].content[0].text.\n",
    ">\n",
    "> Some of our official SDKs include an output_text property on model responses for convenience, which aggregates all text outputs from the model into a single string. This may be useful as a shortcut to access text output from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8fe9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f76cba",
   "metadata": {},
   "source": [
    "# Adding a System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bb5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an anthropologist specializing in ancient fables.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5942d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_ant = \"\"\"\n",
    "Ants were once men and made their living by tilling the soil. \n",
    "But, not content with the results of their own work, they were \n",
    "always casting longing eyes upon the crops and fruits of their \n",
    "neighbours, which they stole, whenever they got the chance, and \n",
    "added to their own store. At last their covetousness made Jupiter \n",
    "so angry that he changed them into Ants. But, though their forms \n",
    "were changed, their nature remained the same: and so, to this day, \n",
    "they go about among the cornfields and gather the fruits of others’ \n",
    "labour, and store them up for their own use.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"01_introduction.ipynb\n",
    "    Please, extract the main message of this fable written by Aesop.\n",
    "    The fable is the following: \\n {the_ant}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a5302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions = system_prompt,\n",
    "    input = prompt,\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaca978",
   "metadata": {},
   "source": [
    "# APIs and SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d93c62",
   "metadata": {},
   "source": [
    "+ OpenAI's Python library is an interface between our code written in Python and a RESTful API provided by OpenAI, a model provider.\n",
    "+ These type of interfaces are sometimes called Software Development Kit (SDK).\n",
    "+ You can read more in OpenAI's Documentation. A few good places to start are:\n",
    "\n",
    "    - Python library's [Github repo](https://github.com/openai/openai-python?tab=readme-ov-file) has a good quickstart.\n",
    "    - [Responses API](https://platform.openai.com/docs/api-reference/responses/) reference. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795e95f",
   "metadata": {},
   "source": [
    "## About the API\n",
    "\n",
    "From the [documentation](https://platform.openai.com/docs/api-reference/responses):\n",
    "\n",
    "> OpenAI's most advanced interface for generating model responses. Supports text and image inputs, and text outputs. Create stateful interactions with the model, using the output of previous responses as input. Extend the model's capabilities with built-in tools for file search, web search, computer use, and more. Allow the model access to external systems and data using function calling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2ecfed",
   "metadata": {},
   "source": [
    "## Abou the Python Library\n",
    "\n",
    "In summary, we used some form of the code below:\n",
    "\n",
    "```{python}\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model = <a model>,\n",
    "    instructions = <a system prompt>,\n",
    "    input = <a user prompt>,\n",
    ")\n",
    "\n",
    "print(response.output_text)\n",
    "\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
