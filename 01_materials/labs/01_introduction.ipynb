{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6711f7",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe804593",
   "metadata": {},
   "source": [
    "## APIs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a712f76e",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca2330f",
   "metadata": {},
   "source": [
    "### Update System Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe751dbe",
   "metadata": {},
   "source": [
    "- Add system path.\n",
    "- This allows us to reutilize our modules in this notebook.\n",
    "- We may want to avoid duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6accefb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../05_src/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e30d88",
   "metadata": {},
   "source": [
    "### Use a Logger\n",
    "\n",
    "- Allows observability and retains your logs.\n",
    "- Log formats are customizable and you can include items like timestamp, module, function, line number, and so on.\n",
    "- Log level is also customizable:\n",
    "\n",
    "    + INFO for regular operations.\n",
    "    + DEBUG for development.\n",
    "    + ERROR and WARNING will be logged.\n",
    "\n",
    "- Useful documents on logging:\n",
    "\n",
    "    - [Python logging library](https://docs.python.org/3/library/logging.html).\n",
    "    - [Real Python: Logging](https://realpython.com/python-logging/).\n",
    "    - [The Hitchhiker's Guide to Python: Logging](https://docs.python-guide.org/writing/logging/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bd2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logger import get_logger\n",
    "_logs = get_logger(__name__, log_dir='../../06_logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da49a967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 14:20:21,996, 999434666.py, 1, INFO, This is a log message.\n"
     ]
    }
   ],
   "source": [
    "_logs.info('This is a log message.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f0942",
   "metadata": {},
   "source": [
    "### Loading Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71fc7085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('../../05_src/.secrets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ce15f",
   "metadata": {},
   "source": [
    "### About .secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328dd79e",
   "metadata": {},
   "source": [
    "# Hello World!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ed6301",
   "metadata": {},
   "source": [
    "+ The [OpenAI Python library](https://github.com/openai/openai-python?tab=readme-ov-file)\n",
    "+ OpenAI API Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fecd195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5261a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model = 'gpt-4o',\n",
    "    input = 'Hello world!',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05951acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'resp_0ba38d4cedef9fca0068dc1f6be0e48193a70319fc1275d5e7',\n",
       " 'created_at': 1759256427.0,\n",
       " 'error': None,\n",
       " 'incomplete_details': None,\n",
       " 'instructions': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4o-2024-08-06',\n",
       " 'object': 'response',\n",
       " 'output': [{'id': 'msg_0ba38d4cedef9fca0068dc1f6ccd588193a1d31a7bead1543a',\n",
       "   'content': [{'annotations': [],\n",
       "     'text': 'Hello! How can I assist you today?',\n",
       "     'type': 'output_text',\n",
       "     'logprobs': []}],\n",
       "   'role': 'assistant',\n",
       "   'status': 'completed',\n",
       "   'type': 'message'}],\n",
       " 'parallel_tool_calls': True,\n",
       " 'temperature': 1.0,\n",
       " 'tool_choice': 'auto',\n",
       " 'tools': [],\n",
       " 'top_p': 1.0,\n",
       " 'background': False,\n",
       " 'max_output_tokens': None,\n",
       " 'max_tool_calls': None,\n",
       " 'previous_response_id': None,\n",
       " 'prompt_cache_key': None,\n",
       " 'reasoning': {'effort': None, 'summary': None},\n",
       " 'safety_identifier': None,\n",
       " 'service_tier': 'default',\n",
       " 'status': 'completed',\n",
       " 'text': {'format': {'type': 'text'}, 'verbosity': 'medium'},\n",
       " 'top_logprobs': 0,\n",
       " 'truncation': 'disabled',\n",
       " 'usage': {'input_tokens': 10,\n",
       "  'input_tokens_details': {'cached_tokens': 0},\n",
       "  'output_tokens': 10,\n",
       "  'output_tokens_details': {'reasoning_tokens': 0},\n",
       "  'total_tokens': 20},\n",
       " 'user': None,\n",
       " 'billing': {'payer': 'developer'},\n",
       " 'store': True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a3c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response.output)\n",
    "response.output[0].content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150e68af",
   "metadata": {},
   "source": [
    "# Longer Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f829ef4f",
   "metadata": {},
   "source": [
    "- Let's try to add more context to our prompt.\n",
    "- Python's [request](https://pypi.org/project/requests/) library and [documentation](https://requests.readthedocs.io/en/latest/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44042a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "file_url = 'https://www.gutenberg.org/cache/epub/204/pg204.txt'\n",
    "book = requests.get(file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5781e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(book.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484ffc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(book.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3aa66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "    You are a literary historian. \n",
    "    Given the following context from a book, please summarize it in a concise manner. \n",
    "    Use no more than 4 sentences. \n",
    "    The book is the following: \\n {book.text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dad9872",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model = 'gpt-4o',\n",
    "    input = prompt,\n",
    ")\n",
    "response.output[0].content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86928b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e353e82",
   "metadata": {},
   "source": [
    "**Note**: From the [documentation](https://platform.openai.com/docs/guides/text?api-mode=responses) we know that,\n",
    "\n",
    "> The output array often has more than one item in it! It can contain tool calls, data about reasoning tokens generated by reasoning models, and other items. It is not safe to assume that the model's text output is present at output[0].content[0].text.\n",
    ">\n",
    "> Some of our official SDKs include an output_text property on model responses for convenience, which aggregates all text outputs from the model into a single string. This may be useful as a shortcut to access text output from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8fe9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f76cba",
   "metadata": {},
   "source": [
    "# Adding a System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bb5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an anthropologist specializing in ancient fables.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5942d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_ant = \"\"\"\n",
    "Ants were once men and made their living by tilling the soil. \n",
    "But, not content with the results of their own work, they were \n",
    "always casting longing eyes upon the crops and fruits of their \n",
    "neighbours, which they stole, whenever they got the chance, and \n",
    "added to their own store. At last their covetousness made Jupiter \n",
    "so angry that he changed them into Ants. But, though their forms \n",
    "were changed, their nature remained the same: and so, to this day, \n",
    "they go about among the cornfields and gather the fruits of others’ \n",
    "labour, and store them up for their own use.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"01_introduction.ipynb\n",
    "    Please, extract the main message of this fable written by Aesop.\n",
    "    The fable is the following: \\n {the_ant}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a5302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions = system_prompt,\n",
    "    input = prompt,\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaca978",
   "metadata": {},
   "source": [
    "# APIs and SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d93c62",
   "metadata": {},
   "source": [
    "+ OpenAI's Python library is an interface between our code written in Python and a RESTful API provided by OpenAI, a model provider.\n",
    "+ These type of interfaces are sometimes called Software Development Kit (SDK).\n",
    "+ You can read more in OpenAI's Documentation. A few good places to start are:\n",
    "\n",
    "    - Python library's [Github repo](https://github.com/openai/openai-python?tab=readme-ov-file) has a good quickstart.\n",
    "    - [Responses API](https://platform.openai.com/docs/api-reference/responses/) reference. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795e95f",
   "metadata": {},
   "source": [
    "## About the API\n",
    "\n",
    "From the [documentation](https://platform.openai.com/docs/api-reference/responses):\n",
    "\n",
    "> OpenAI's most advanced interface for generating model responses. Supports text and image inputs, and text outputs. Create stateful interactions with the model, using the output of previous responses as input. Extend the model's capabilities with built-in tools for file search, web search, computer use, and more. Allow the model access to external systems and data using function calling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2ecfed",
   "metadata": {},
   "source": [
    "## Abou the Python Library\n",
    "\n",
    "In summary, we used some form of the code below:\n",
    "\n",
    "```{python}\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model = <a model>,\n",
    "    instructions = <a system prompt>,\n",
    "    input = <a user prompt>,\n",
    ")\n",
    "\n",
    "print(response.output_text)\n",
    "\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
