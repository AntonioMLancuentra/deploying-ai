{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1107f1ba",
   "metadata": {},
   "source": [
    "# Vector DB\n",
    "\n",
    "In this notebook, we use a containerized version of Chroma DB. To set up, you will need the following:\n",
    "\n",
    "1. Install [Docker Desktop](https://www.docker.com/products/docker-desktop/) by following the link and Download Docker Desktop for your operating system.\n",
    "2. In a terminal window, navigate to the folder ./05_src/chromadb/. For example, on Windows, you would use `cd .\\05_src\\chromadb`.\n",
    "3. Run the command `docker compose up -d`, which will start the Chroma DB server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e149c1f7",
   "metadata": {},
   "source": [
    "## Downloading Batch Results\n",
    "\n",
    "In the previous notebook, we had created batch processes. We will start by consulting the status of our batch processes by identifying them throught their descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b8faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../../05_src/.secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52811dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_description = 'Pitchfork reviews content embeddings 2025-10-18 12:17:17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1493892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "batch_processes = client.batches.list().to_dict()\n",
    "batch_info= [\n",
    "    {'batch_id': batch['id'],\n",
    "     'description': batch['metadata']['description'],\n",
    "    'status': batch['status'],\n",
    "    'request_counts': batch['request_counts'],\n",
    "    'output_file_id': batch['output_file_id'],\n",
    "    'input_file_id': batch['input_file_id']}\n",
    "            for batch in batch_processes['data'] if batch['metadata']['description'] == batch_description\n",
    "    ]\n",
    "batch_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee88934",
   "metadata": {},
   "source": [
    "When the status of the batches is complete, we can query the `output_file_id` where their results will be stored.\n",
    "\n",
    "More generally, we will require the original text and the embeddings of that original text mapped through the `custom_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776b7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_complete = [\n",
    "    batch  for batch in batch_info if batch['status'] == 'completed'\n",
    "]\n",
    "batch_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f0d274",
   "metadata": {},
   "source": [
    "Before we download all results, examine the response of the file API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb263665",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.files.content(batch_complete[0]['output_file_id'])\n",
    "text_response = response.text\n",
    "lines = text_response.split('\\n')\n",
    "print(lines[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91738746",
   "metadata": {},
   "source": [
    "For our results database, we will need to map the original text to their embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313020f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "def get_text_and_embeddings(batch):\n",
    "    embedding_lines =  get_content_from_file(batch, 'output_file_id')\n",
    "    text_lines = get_content_from_file(batch, 'input_file_id')\n",
    "    return embedding_lines, text_lines\n",
    "\n",
    "def get_content_from_file(batch, key):\n",
    "    file = client.files.content(batch[key])\n",
    "    text = file.text\n",
    "    lines = text.split('\\n')\n",
    "    content_lines = [json.loads(line) for line in lines if line.strip()]\n",
    "    return content_lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6021e7b4",
   "metadata": {},
   "source": [
    "Notice that the response is also a .jsonl file. Therefore, we can process it line-by-line and use the `custom_id` to map to the original document chunk.\n",
    "\n",
    "The function below:\n",
    "\n",
    "- Creates a dictionary, `text_dict`, with keys given by each `custom_id` and value equal to the text.\n",
    "- Iterate over all embedding items and use the dictionary defined above to map the embeddings to their input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19fc426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chroma_inputs(embedding_lines, text_lines):\n",
    "    chroma_inputs = []\n",
    "    text_dict = {item['custom_id']: item['body']['input'] for item in text_lines}\n",
    "    for embed_item in embedding_lines:\n",
    "        custom_id = embed_item['custom_id']\n",
    "        text = text_dict.get(custom_id, \"\")\n",
    "        chroma_input = {\n",
    "            'id': embed_item['custom_id'],\n",
    "            'embedding': embed_item['response']['body']['data'][0]['embedding'],\n",
    "            'text': text\n",
    "        }\n",
    "        chroma_inputs.append(chroma_input)\n",
    "    return chroma_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e1ef45",
   "metadata": {},
   "source": [
    "A couple of functions to control the logic flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc6975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def process_batch_for_chromadb(batch):\n",
    "    embedding_lines, text_lines = get_text_and_embeddings(batch)\n",
    "    chroma_inputs = create_chroma_inputs(embedding_lines, text_lines)\n",
    "    return chroma_inputs\n",
    "\n",
    "def process_batches_for_chromadb(batches):\n",
    "    all_chroma_inputs = []\n",
    "    for batch in tqdm(batches, desc=\"Processing batches\"):\n",
    "        chroma_inputs = process_batch_for_chromadb(batch)\n",
    "        all_chroma_inputs.extend(chroma_inputs)\n",
    "    return all_chroma_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a6c05b",
   "metadata": {},
   "source": [
    "Now, we can create our input dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83c57f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_inputs = process_batches_for_chromadb(batch_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286dfab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_inputs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0c572",
   "metadata": {},
   "source": [
    "# Load Embeddings to Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae13f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "import os\n",
    "\n",
    "\n",
    "def setup_collection(chroma_url:str=\"http://localhost:8000\",\n",
    "                     collection_name: str = \"pitchfork_reviews\"):\n",
    "    chroma_client = chromadb.HttpClient(host=chroma_url)\n",
    "    collections = chroma_client.list_collections()\n",
    "    if collection_name in [col.name for col in collections]:\n",
    "        chroma_client.delete_collection(name=collection_name)\n",
    "\n",
    "    collection = chroma_client.create_collection(\n",
    "        name=collection_name,\n",
    "        embedding_function=OpenAIEmbeddingFunction(\n",
    "            api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "            model_name=\"text-embedding-3-small\")\n",
    "        )\n",
    "    return collection\n",
    "\n",
    "def load_embeddings_to_db(chroma_inputs:list[dict], \n",
    "                          collection_name:str,\n",
    "                          chroma_url:str=\"http://localhost:8000\",\n",
    "                          batch_size:int= 1000\n",
    "                          ):\n",
    "\n",
    "    \n",
    "    collection = setup_collection(chroma_url=chroma_url, collection_name=collection_name)\n",
    "\n",
    "    for i in tqdm(range(0, len(chroma_inputs), batch_size)):\n",
    "        batch = chroma_inputs[i:i + batch_size]\n",
    "        collection.add(\n",
    "            documents=[item['text'] for item in batch],\n",
    "            embeddings=[item['embedding'] for item in batch],\n",
    "            ids=[item['id'] for item in batch]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db_client_url:str=\"http://localhost:8000\"\n",
    "load_embeddings_to_db(chroma_inputs=chroma_inputs,\n",
    "                      collection_name=\"pitchfork_reviews\",\n",
    "                      chroma_url=vector_db_client_url, \n",
    "                      batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a549b1f1",
   "metadata": {},
   "source": [
    "# Additional Details\n",
    "\n",
    "We will use a simple database to store additional details about the reviews. In this case, we load the jsonl files, and use pandas to create a few tables in a sql database. The connection string to the database is included in the .secrets file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61ceec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_jsonl(file:str):\n",
    "    data = []\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                data.append(json.loads(line))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68642813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "import os\n",
    "\n",
    "doc_folder = \"../../05_src/documents/\"\n",
    "tables = [\"artists\", \"reviews\", \"labels\", \"genres\"]\n",
    "\n",
    "def upload_tables_to_sql(tables:list[str], doc_folder:str):\n",
    "    engine = sa.create_engine(os.getenv(\"SQL_URL\"))\n",
    "    for table_name in tables:\n",
    "        file_path = os.path.join(doc_folder, f\"pitchfork_{table_name}.jsonl\")\n",
    "        data = load_jsonl(file_path)\n",
    "        df = pd.DataFrame(data)\n",
    "        with engine.connect() as conn:\n",
    "            df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "        print(f\"Loaded {df.shape} records from {file_path}\")\n",
    "\n",
    "upload_tables_to_sql(tables=tables, doc_folder=doc_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d3063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_details(review_id:str):\n",
    "    import sqlalchemy as sa\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    engine = sa.create_engine(os.getenv(\"SQL_URL\"))\n",
    "    query = f\"\"\"\n",
    "    SELECT r.reviewid,\n",
    "\t\tr.title,\n",
    "\t\tr.artist,\n",
    "\t\tr.score,\n",
    "\t\tg.genre\n",
    "    FROM reviews AS r\n",
    "    LEFT JOIN genres as g\n",
    "\t    ON r.reviewid = g.reviewid\n",
    "    WHERE r.reviewid = '{review_id}'\n",
    "    \"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        result = pd.read_sql(query, conn)\n",
    "    if not result.empty:\n",
    "        row = result.iloc[0]\n",
    "        details = {\n",
    "            \"reviewid\": row['reviewid'],\n",
    "            \"album\": row['title'],\n",
    "            \"score\": row['score'],\n",
    "            \"artist\": row['artist']\n",
    "        }\n",
    "        return details\n",
    "    else:\n",
    "        return {}\n",
    "    \n",
    "def get_reviewid_from_custom_id(custom_id:str):\n",
    "    return custom_id.split('_')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511bd042",
   "metadata": {},
   "source": [
    "# Prompt Generator\n",
    "\n",
    "Here we create a prompt with the context gathered through the different data operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e82559",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma = chromadb.HttpClient(host=vector_db_client_url)\n",
    "collection = chroma.get_collection(name=\"pitchfork_reviews\", \n",
    "                                   embedding_function=OpenAIEmbeddingFunction(\n",
    "                                       api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "                                       model_name=\"text-embedding-3-small\")\n",
    "                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e3d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.query(\n",
    "    query_texts=[\"A great album with stunning vocals and production.\"],\n",
    "    n_results=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91701baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_data(query:str, collection:chromadb.api.models.Collection, top_n:int):\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=top_n\n",
    "    )\n",
    "    context_data = []\n",
    "    for idx, custom_id in enumerate(results['ids'][0]):\n",
    "        review_id = get_reviewid_from_custom_id(custom_id)\n",
    "        details = additional_details(review_id)\n",
    "        details['text'] = results['documents'][0][idx]\n",
    "        context_data.append(details)\n",
    "    return context_data\n",
    "\n",
    "def generate_prompt(query:str, collection:chromadb.api.models.Collection, top_n:int):\n",
    "    context_data = get_context_data(query, collection, top_n)\n",
    "    prompt = f\"Given a query, provide a detailed response using the context from relevant Pitchfork reviews. The context will contain references to {top_n} album reviews.\\n\\n\"\n",
    "    prompt += f\"The score is numeric and its scale is from 0 to 10, with 10 being the highest rating. Any album with a score greater than 8.0 is considered a must-listen; album with a score greater than 6.5 is good.\\n\\n\"\n",
    "    prompt += f\"<query>{query}</query>\\n\\n\"\n",
    "    prompt += \"<context>\\n\"\n",
    "    for k, context in enumerate(context_data):\n",
    "        prompt += f\"<album {k}>\\n\"\n",
    "        prompt += f\"- Album Title: {context.get('album', 'N/A')}\\n\" \n",
    "        prompt += f\"- Album Artist: {context.get('artist', 'N/A')}\\n\"\n",
    "        prompt += f\"- Album Score: {context.get('score', 'N/A')}\\n\"\n",
    "        prompt += f\"- Review Quote: {context.get('text', 'N/A')}\\n\"\n",
    "        prompt += f\"</album {k}>\\n\\n\"\n",
    "    prompt += \"</context>\\n\\n\"\n",
    "    prompt += \"\\nBased on the context and nothing else, provide a detailed response to the query.\"\n",
    "    return prompt\n",
    "\n",
    "def generate_response(query:str, collection:chromadb.api.models.Collection, top_n:int=1):\n",
    "    prompt = generate_prompt(query, collection, top_n)\n",
    "    print(\"Generated Prompt:\\n\", prompt)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that provides information based on Pitchfork reviews.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=500,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766798f3",
   "metadata": {},
   "source": [
    "# Query\n",
    "\n",
    "We can now use chroma's similarity function to query the database. Notice that the query itself needs to be converted to embeddings, so we must provide an `embedding_function`. In this case, we use `OpenAIEmbeddingFunction()` to get compatible embeddings using model `text-embedding-3-small`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c96406",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generate_response(\"What are some highly rated albums by emerging indie artists?\", collection, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99610fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64618a45",
   "metadata": {},
   "source": [
    "**Note**: Try changing the top_n parameter to 1 and re-run the query. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
