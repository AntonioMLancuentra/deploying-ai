{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1107f1ba",
   "metadata": {},
   "source": [
    "# Vector DB\n",
    "\n",
    "In this notebook, we use a containerized version of Chroma DB. To set up, you will need the following:\n",
    "\n",
    "1. Install [Docker Desktop](https://www.docker.com/products/docker-desktop/) by following the link and Download Docker Desktop for your operating system.\n",
    "2. In a terminal window, navigate to the folder ./05_src/chromadb/. For example, on Windows, you would use `cd .\\05_src\\chromadb`.\n",
    "3. Run the command `docker compose up -d`, which will start the Chroma DB server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e149c1f7",
   "metadata": {},
   "source": [
    "## Downloading Batch Results\n",
    "\n",
    "In the previous notebook, we had created batch processes. We will start by consulting the status of our batch processes by identifying them throught their descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b8faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../../05_src/.secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52811dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_description = 'Pitchfork reviews content embeddings 2025-10-18 12:17:17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1493892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "batch_processes = client.batches.list().to_dict()\n",
    "batch_info= [\n",
    "    {'batch_id': batch['id'],\n",
    "     'description': batch['metadata']['description'],\n",
    "    'status': batch['status'],\n",
    "    'request_counts': batch['request_counts'],\n",
    "    'output_file_id': batch['output_file_id'],\n",
    "    'input_file_id': batch['input_file_id']}\n",
    "            for batch in batch_processes['data'] if batch['metadata']['description'] == batch_description\n",
    "    ]\n",
    "batch_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee88934",
   "metadata": {},
   "source": [
    "When the status of the batches is complete, we can query the `output_file_id` where their results will be stored.\n",
    "\n",
    "More generally, we will require the original text and the embeddings of that original text mapped through the `custom_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776b7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_complete = [\n",
    "    batch  for batch in batch_info if batch['status'] == 'completed'\n",
    "]\n",
    "batch_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f0d274",
   "metadata": {},
   "source": [
    "Before we download all results, examine the response of the file API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb263665",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.files.content(batch_complete[0]['output_file_id'])\n",
    "text_response = response.text\n",
    "lines = text_response.split('\\n')\n",
    "print(lines[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91738746",
   "metadata": {},
   "source": [
    "For our results database, we will need to map the original text to their embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313020f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "def get_text_and_embeddings(batch):\n",
    "    embedding_lines =  get_content_from_file(batch, 'output_file_id')\n",
    "    text_lines = get_content_from_file(batch, 'input_file_id')\n",
    "    return embedding_lines, text_lines\n",
    "\n",
    "def get_content_from_file(batch, key):\n",
    "    file = client.files.content(batch[key])\n",
    "    text = file.text\n",
    "    lines = text.split('\\n')\n",
    "    content_lines = [json.loads(line) for line in lines if line.strip()]\n",
    "    return content_lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6021e7b4",
   "metadata": {},
   "source": [
    "Notice that the response is also a .jsonl file. Therefore, we can process it line-by-line and use the `custom_id` to map to the original document chunk.\n",
    "\n",
    "The functio below:\n",
    "\n",
    "- Creates a dictionary, `text_dict`, with keys given by each `custom_id` and value equal to the text.\n",
    "- Iterate over all embedding items and use the dictionary defined above to map the embeddings to their input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19fc426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chroma_inputs(embedding_lines, text_lines):\n",
    "    chroma_inputs = []\n",
    "    text_dict = {item['custom_id']: item['body']['input'] for item in text_lines}\n",
    "    for embed_item in embedding_lines:\n",
    "        custom_id = embed_item['custom_id']\n",
    "        text = text_dict.get(custom_id, \"\")\n",
    "        chroma_input = {\n",
    "            'id': embed_item['custom_id'],\n",
    "            'embedding': embed_item['response']['body']['data'][0]['embedding'],\n",
    "            'text': text\n",
    "        }\n",
    "        chroma_inputs.append(chroma_input)\n",
    "    return chroma_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e1ef45",
   "metadata": {},
   "source": [
    "A couple of functions to control the logic flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc6975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_for_chromadb(batch):\n",
    "    embedding_lines, text_lines = get_text_and_embeddings(batch)\n",
    "    chroma_inputs = create_chroma_inputs(embedding_lines, text_lines)\n",
    "    return chroma_inputs\n",
    "\n",
    "def process_batches_for_chromadb(batches):\n",
    "    all_chroma_inputs = []\n",
    "    for batch in batches:\n",
    "        chroma_inputs = process_batch_for_chromadb(batch)\n",
    "        all_chroma_inputs.extend(chroma_inputs)\n",
    "    return all_chroma_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a6c05b",
   "metadata": {},
   "source": [
    "Now, we can create our input dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83c57f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_inputs = process_batches_for_chromadb(batch_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286dfab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_inputs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0c572",
   "metadata": {},
   "source": [
    "# Load Embeddings to Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ae13f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def setup_collection(chroma_url:str=\"http://localhost:8000\",\n",
    "                     collection_name: str = \"pitchfork_reviews\"):\n",
    "    chroma_client = chromadb.HttpClient(host=chroma_url)\n",
    "    collections = chroma_client.list_collections()\n",
    "    if collection_name in [col.name for col in collections]:\n",
    "        chroma_client.delete_collection(name=collection_name)\n",
    "\n",
    "    collection = chroma_client.create_collection(\n",
    "        name=collection_name,\n",
    "        embedding_function=OpenAIEmbeddingFunction(\n",
    "            api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "            model_name=\"text-embedding-3-small\")\n",
    "        )\n",
    "    return collection\n",
    "\n",
    "def load_embeddings_to_db(chroma_inputs:list[dict], \n",
    "                          collection_name:str,\n",
    "                          chroma_url:str=\"http://localhost:8000\",\n",
    "                          batch_size:int= 1000\n",
    "                          ):\n",
    "\n",
    "    \n",
    "    collection = setup_collection(chroma_url=chroma_url, collection_name=collection_name)\n",
    "\n",
    "    for i in tqdm(range(0, len(chroma_inputs), batch_size)):\n",
    "        batch = chroma_inputs[i:i + batch_size]\n",
    "        collection.add(\n",
    "            documents=[item['text'] for item in batch],\n",
    "            embeddings=[item['embedding'] for item in batch],\n",
    "            ids=[item['id'] for item in batch]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db_client_url:str=\"http://localhost:8000\"\n",
    "load_embeddings_to_db(chroma_inputs=chroma_inputs,\n",
    "                      collection_name=\"pitchfork_reviews\",\n",
    "                      chroma_url=vector_db_client_url, \n",
    "                      batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766798f3",
   "metadata": {},
   "source": [
    "# Query\n",
    "\n",
    "We can now use chroma's similarity function to query the database. Notice that the query itself needs to be converted to embeddings, so we must provide an `embedding_function`. In this case, we use `OpenAIEmbeddingFunction()` to get compatible embeddings using model `text-embedding-3-small`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df1f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma = chromadb.HttpClient(host=vector_db_client_url)\n",
    "collection = chroma.get_collection(name=\"pitchfork_reviews\", \n",
    "                                   embedding_function=OpenAIEmbeddingFunction(\n",
    "                                       api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "                                       model_name=\"text-embedding-3-small\")\n",
    "                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.query(\n",
    "    query_texts=[\"A great album with stunning vocals and production.\"],\n",
    "    n_results=3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
