{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "572a0e2a",
   "metadata": {},
   "source": [
    "# Evaluating Model Outputs\n",
    "\n",
    "This notebook demonstrates how to obtain and use logprobs from the Completions API. Many of these examples are adapted from the [\"Using logprobs\" from the OpenAI Cookbook](https://cookbook.openai.com/examples/using_logprobs#0-imports-and-utils).\n",
    "\n",
    "\n",
    "## Logprobs and Classification\n",
    "\n",
    "The first thing to notice is that the Responses and Completions APIs can return logprobs. Not every model provider will return logprobs. Two key parameters to obtain logprobs are:\n",
    "\n",
    "- `logprobs`: whether to retunr the log rpobabilities of the output tokens. If true, returns the logprobs of each output token returned in the content message.\n",
    "- `top_logprobs`: An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. This parameter requires `logprobs = True`.\n",
    "\n",
    "Log probabilities or logprobs are $log(p)$ where $p$ is the probability of a token occurring at a specific position based on the previous tokens in the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../../05_src/.secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c35aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import os\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28db224",
   "metadata": {},
   "source": [
    "First, we establish a simple interface that we can use for our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(\n",
    "    input: list[dict[str, str]],\n",
    "    model: str = \"gpt-4o-mini\",\n",
    "    max_tokens=500,\n",
    "    temperature=0,\n",
    "    tools=None,\n",
    "    logprobs=None,  # whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of message..\n",
    "    top_logprobs=None,\n",
    ") -> str:\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"input\": input,\n",
    "        \"max_output_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"tools\": tools,\n",
    "        \"include\": [\"message.output_text.logprobs\"] if logprobs else [],\n",
    "        \"top_logprobs\": top_logprobs,\n",
    "    }\n",
    "    if tools:\n",
    "        params[\"tools\"] = tools\n",
    "\n",
    "    completion = client.responses.create(**params)\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c2322",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = [\n",
    "    \"War and Peace in the Modern Era\",\n",
    "    \"'War and Peace' in the Modern Era\",\n",
    "    \"The Art of the Deal\",\n",
    "    # NYT\n",
    "    \"Louvre Closed After Thieves Steal ‘Priceless’ Jewels in Brazen Daylight Robbery\",\n",
    "    \"The Risk That Built America\",\n",
    "    \"Who should the Dodgers rather face in the World Series, the Mariners or the Blue Jays?\",\n",
    "    #New Yorker\n",
    "    \"Justin Trudeau and Katy Perry's Teen-Age Dream\",\n",
    "    \"Shohei Ohtani and the Dodgers Are a Sight to Behold\", \n",
    "    \"A Tech Millionaire's Costly Quest to Prove His Brother Was Murdered\", \n",
    "    \"The AI Boom and the Spectre of 1929\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90122d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFICATION_PROMPT = \"\"\"You will be given a headline of a news article.\n",
    "Classify the article into one of the following categories: Business,  Politics, Sports, and Art.\n",
    "Return only the name of the category, and nothing else.\n",
    "MAKE SURE your output is one of the four categories stated.\n",
    "Article headline: {headline}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1941f506",
   "metadata": {},
   "source": [
    "We can use the interface to obtain the classification that we requested. However, it does not show the logprobs of the different top options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20b0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "for headline in headlines:\n",
    "    print(f\"\\nHeadline: {headline}\")\n",
    "    response = get_completion(\n",
    "        [{\"role\": \"user\", \"content\": CLASSIFICATION_PROMPT.format(headline=headline)}],\n",
    "        model=\"gpt-4o-mini\",\n",
    "    )\n",
    "    print(f\"Category: {response.output_text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc17e8f",
   "metadata": {},
   "source": [
    "Showing the top two options with their log and linear probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ca0760",
   "metadata": {},
   "outputs": [],
   "source": [
    "for headline in headlines:\n",
    "    print(f\"\\nHeadline: {headline}\")\n",
    "    API_RESPONSE = get_completion(\n",
    "        [{\"role\": \"user\", \"content\": CLASSIFICATION_PROMPT.format(headline=headline)}],\n",
    "        model=\"gpt-4o-mini\",\n",
    "        logprobs=True,\n",
    "        top_logprobs=2,\n",
    "    )\n",
    "    top_n_logprobs = API_RESPONSE.output[0].content[0].logprobs[0].top_logprobs\n",
    "    output_content = \"\"\n",
    "    for i, logprob in enumerate(top_n_logprobs, start=1):\n",
    "        output_content += (\n",
    "            f\"Output token {i}: {logprob.token}, \"\n",
    "            f\"logprobs: {logprob.logprob}, \"\n",
    "            f\"linear probability: {np.round(np.exp(logprob.logprob)*100,2)}%\\n\"\n",
    "        )\n",
    "    print(output_content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b97a23b",
   "metadata": {},
   "source": [
    "In this classification task, we see the usefulness of logprobs: \n",
    "+ We can determine the degree to which a model is \"sure\" about a classification that it has proposed. \n",
    "+ Based on logprobs, we can set a threshold under which human assistance is needed. \n",
    "+ Alternatively, we can set the logic of our code to provide several options if the logprobs are within a threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15336b94",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
