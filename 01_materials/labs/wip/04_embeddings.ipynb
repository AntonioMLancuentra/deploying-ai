{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ac9fa3b",
   "metadata": {},
   "source": [
    "# Representing Text\n",
    "\n",
    "We can represent text in many ways: character strings are a standard representation, but we can also create numerical representations of text. In this notebook we will discuss embeddings.\n",
    "\n",
    "## Features\n",
    "\n",
    "Features to any (machine learning) model can be continuous or categorical.\n",
    "\n",
    "- We use continuous features to represent numerical values: income, number of times the user clicked on a link, prices, etc.\n",
    "- Categorical features represent an instance of a class or category. They have a finite number of possible values: job title, genre of a movie, breed of a dog, etc.\n",
    "\n",
    "## Embeddings\n",
    "\n",
    "An **embedding** is a trained numerical representation of a categorical feature:\n",
    "\n",
    "- We use the word *trained* to highlight that embeddings are learned during model training.\n",
    "- Different models and training procedures can be used to obtained embeddings. Word2Vec and BERT embeddings, for example, are different and capture different characteristics of the features.\n",
    "\n",
    "[OpenAI's documentation](https://platform.openai.com/docs/guides/embeddings) include a few uses of embeddings:\n",
    "\n",
    "\n",
    "- Search: results are ranked by relevance to a query string.\n",
    "- Clustering:  text strings are grouped by similarity.\n",
    "- Recommendations:  items with related text strings are recommended.\n",
    "- Anomaly detection:  outliers with little relatedness are identified.\n",
    "- Diversity measurement: similarity distributions are analyze.\n",
    "- Classification: text strings are classified by their most similar label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f396f4",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Most embedding computations start with the process of tokenization. Specifically, we can use the [`transformers`](https://huggingface.co/docs/transformers/en/index) library from [HuggingFace](https://huggingface.co/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0957363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 8870, 2024, 4569, 102]], 'token_type_ids': [[0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "\n",
    "\n",
    "documents = [\"cats are fun\"]\n",
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased')\n",
    "tokens = tokenizer(documents)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e29323",
   "metadata": {},
   "source": [
    "In the code snippet above, we used the `transformers` library to obtain the tokens that represent the phrase 'cats are fun'. The tokenizer returns a dictionary with an entry called `'input_ids'`, which contains an array (tensor if we were working on TensorFlow) of four integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70b566b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d340a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../../05_src/.secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c2f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "else:\n",
    "    client = OpenAI(api_key = OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab09379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6890865",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    # Freedom\n",
    "    \"Freedom consists not in doing what we like, but in having the right to do what we ought.\",\n",
    "    \"Those who deny freedom to others deserve it not for themselves.\",\n",
    "    \"Liberty, when it begins to take root, is a plant of rapid growth.\",\n",
    "    \"Freedom lies in being bold.\",\n",
    "    \"Is freedom anything else than the right to live as we wish?\",\n",
    "    \"I am no bird and no net ensnares me: I am a free human being with an independent will.\",\n",
    "    \"The secret to happiness is freedom... And the secret to freedom is courage.\"\n",
    "    \"Freedom is the oxygen of the soul.\", \n",
    "    \"Life without liberty is like a body without spirit.\"\n",
    "    # Friendship\n",
    "    \"There is nothing on this earth more to be prized than true friendship.\",\n",
    "    \"There are no strangers here; Only friends you havenâ€™t yet met.\",\n",
    "    \"Friendship is the only cement that will ever hold the world together.\",\n",
    "    \"A true friend is someone who is there for you when he'd rather be anywhere else.\",\n",
    "    \"Friendship is the golden thread that ties the heart of all the world.\", \n",
    "    \"Your friend is the man who knows all about you and still likes you.\",\n",
    "    \"A single rose can be my garden... a single friend, my world.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96df878",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [get_embedding(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce0d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_array = np.array(embeddings)\n",
    "embeddings_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775395af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "reduced_embeddings = pca.fit_transform(embeddings_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7068fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(reduced_embeddings, columns=[\"x\", \"y\"]).assign(lables = documents)\n",
    "ax = df.plot(kind='scatter', x='x', y='y', figsize=(8, 6))\n",
    "for i, row in df.iterrows():\n",
    "    ax.text(row['x'], row['y'], row['lables'], fontsize=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
